{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_frames_composite_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WLfl2u0tCTgihkBFXAI1kr6JtejS9cdi",
      "authorship_tag": "ABX9TyP5A0tQElJBhGMGuQzrlaMP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niz11/Bachelor_Thesis_Colab_Files/blob/main/5_frames_composite_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqMB5X65d0wf"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load encoding\n",
        "X = np.load('drive/My Drive/dataset_5_frame_seq_faces/X_5.npy')\n",
        "y = np.load('drive/My Drive/dataset_5_frame_seq_faces/Y_label_5.npy')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n",
        "y_train = to_categorical(y_train, num_classes=7)\n",
        "y_test = to_categorical(y_test, num_classes=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrCCb-XoqRko",
        "outputId": "89ca14cb-804f-46ca-bf52-bd5115232681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input, Flatten, Dense,LSTM,TimeDistributed,RepeatVector\n",
        "from keras.models import Model,Sequential\n",
        "from keras.utils import plot_model\n",
        "\n",
        "\n",
        "def create_model(encoding_length=64,sequence_length=10):\n",
        "  # Define an input sequence and process it.\n",
        "  encoder_inputs = Input(shape=(sequence_length, encoding_length))\n",
        "  encoder = LSTM(encoding_length, return_sequences=True)(encoder_inputs)\n",
        "  encoder_outputs, state_h, state_c  = LSTM(encoding_length, return_state=True, name='encoder')(encoder)\n",
        "  encoder_states = [state_h, state_c]\n",
        "  clssifier  = Dense(7, activation='softmax')(encoder_outputs)\n",
        "\n",
        "  model = Model(inputs=encoder_inputs, outputs=[clssifier])\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  plot_model(model, show_shapes=True, to_file='lstm_autoencoder.png')\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "model = create_model(128, 5)\n",
        "model.load_weights(\"drive/My Drive/trained_models/composite_paper_5/encoderComposite_5.h5\",by_name=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 5, 128)]          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 5, 128)            131584    \n",
            "_________________________________________________________________\n",
            "encoder (LSTM)               [(None, 128), (None, 128) 131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 264,071\n",
            "Trainable params: 264,071\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1oPIMoNrXQi",
        "outputId": "3d066a17-04ab-4ba4-a296-71462ce4e976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "model.fit(X_train, y_train, epochs=10, verbose=1, validation_split=0.05)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60/60 [==============================] - 1s 25ms/step - loss: 1.5537 - accuracy: 0.4225 - val_loss: 1.2809 - val_accuracy: 0.6400\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.8282 - accuracy: 0.7626 - val_loss: 0.8705 - val_accuracy: 0.7700\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.4232 - accuracy: 0.8932 - val_loss: 0.6034 - val_accuracy: 0.8700\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1994 - accuracy: 0.9593 - val_loss: 0.5628 - val_accuracy: 0.8600\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.1172 - accuracy: 0.9783 - val_loss: 0.4270 - val_accuracy: 0.9300\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0694 - accuracy: 0.9878 - val_loss: 0.4965 - val_accuracy: 0.9100\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0493 - accuracy: 0.9915 - val_loss: 0.4423 - val_accuracy: 0.9100\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0318 - accuracy: 0.9926 - val_loss: 0.4652 - val_accuracy: 0.9200\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.4110 - val_accuracy: 0.9200\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 0s 8ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.4661 - val_accuracy: 0.9200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f22a00c9c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR9ePUQbrYPU"
      },
      "source": [
        "def getFaceExpressionFromIndex(i):\n",
        "  if (i == 0):\n",
        "      return 'surprise'\n",
        "  elif (i == 1):\n",
        "      return 'smile'\n",
        "  elif (i == 2):\n",
        "      return 'sad'\n",
        "  elif (i == 3):\n",
        "      return 'anger'\n",
        "  elif (i == 4):\n",
        "      return 'fear'\n",
        "  elif (i == 5):\n",
        "      return 'disgust'\n",
        "  elif (i == 6):\n",
        "      return 'none'\n",
        "  else:\n",
        "      print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMXHiLGurbSX",
        "outputId": "0cbc055e-61d7-45c0-a4e2-db4a86ea1ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_predictions = model.predict(X_test)\n",
        "correct = 0\n",
        "for i in range(len(test_predictions)):\n",
        "  truth = np.argmax(y_test[i])\n",
        "  prediction = np.argmax(test_predictions[i])\n",
        "  if truth == prediction:\n",
        "    correct += 1\n",
        "  else:\n",
        "    print(f'Wrong classification, truth: {getFaceExpressionFromIndex(truth)}')\n",
        "    print(f'Wrong classification, prediction: {getFaceExpressionFromIndex(prediction)}')\n",
        "    print(\"---------------------------------------------------------------------------\")\n",
        "print(f'number of samples: {len(test_predictions)}')\n",
        "print(f'correct: {correct}')\n",
        "print(f'Accuracy of predicitons: {correct / len(test_predictions)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrong classification, truth: anger\n",
            "Wrong classification, prediction: sad\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: sad\n",
            "Wrong classification, prediction: none\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: smile\n",
            "Wrong classification, prediction: none\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: smile\n",
            "Wrong classification, prediction: anger\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: surprise\n",
            "Wrong classification, prediction: anger\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: none\n",
            "Wrong classification, prediction: fear\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: anger\n",
            "Wrong classification, prediction: surprise\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: surprise\n",
            "Wrong classification, prediction: none\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: none\n",
            "Wrong classification, prediction: disgust\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: smile\n",
            "Wrong classification, prediction: anger\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: surprise\n",
            "Wrong classification, prediction: fear\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: none\n",
            "Wrong classification, prediction: smile\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: anger\n",
            "Wrong classification, prediction: surprise\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: anger\n",
            "Wrong classification, prediction: surprise\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: disgust\n",
            "Wrong classification, prediction: sad\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: smile\n",
            "Wrong classification, prediction: surprise\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: surprise\n",
            "Wrong classification, prediction: anger\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: surprise\n",
            "Wrong classification, prediction: anger\n",
            "---------------------------------------------------------------------------\n",
            "number of samples: 222\n",
            "correct: 204\n",
            "Accuracy of predicitons: 0.918918918918919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwUTYBKirfcr"
      },
      "source": [
        "# Here and below is the network to classify the encodings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzprnlIWqNOU",
        "outputId": "d78671b5-cb89-4a79-a8a9-1049e96d1cad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "import json\n",
        "\n",
        "# load json and create model\n",
        "json_file = open('drive/My Drive/trained_models/composite_paper_5/encoderComposite_5.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "encoder = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "encoder.load_weights(\"drive/My Drive/trained_models/composite_paper_5/encoderComposite_5.h5\")\n",
        "print(\"Loaded model from disk\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsFjSMd5emT7"
      },
      "source": [
        "# Check here: better divinding to test/train set\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load encoding\n",
        "X = np.load('drive/My Drive/dataset_5_frame_seq_faces/X_5.npy')\n",
        "y = np.load('drive/My Drive/dataset_5_frame_seq_faces/Y_label_5.npy')\n",
        "\n",
        "predictions = encoder.predict(X)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(predictions, y, test_size = 0.1, random_state = 0)\n",
        "y_train = to_categorical(y_train, num_classes=7)\n",
        "y_test = to_categorical(y_test, num_classes=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHt0fexmfgBy"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "def classifier():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(64, input_dim=128, activation='relu'))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(7, activation='softmax'))\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvPhtD24fjRS",
        "outputId": "338304c7-c334-4953-c54a-2b247307f51d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = classifier()\n",
        "model.fit(X_train, y_train, epochs=50, verbose=1, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "56/56 [==============================] - 0s 6ms/step - loss: 1.8153 - accuracy: 0.2730 - val_loss: 1.8007 - val_accuracy: 0.2900\n",
            "Epoch 2/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.6158 - accuracy: 0.4042 - val_loss: 1.6645 - val_accuracy: 0.4050\n",
            "Epoch 3/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.4493 - accuracy: 0.5003 - val_loss: 1.5150 - val_accuracy: 0.4550\n",
            "Epoch 4/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.2973 - accuracy: 0.5572 - val_loss: 1.4202 - val_accuracy: 0.5350\n",
            "Epoch 5/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.1477 - accuracy: 0.6343 - val_loss: 1.2808 - val_accuracy: 0.5750\n",
            "Epoch 6/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 1.0232 - accuracy: 0.6767 - val_loss: 1.2103 - val_accuracy: 0.6150\n",
            "Epoch 7/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.9159 - accuracy: 0.7097 - val_loss: 1.1004 - val_accuracy: 0.6800\n",
            "Epoch 8/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.8106 - accuracy: 0.7599 - val_loss: 1.0492 - val_accuracy: 0.6950\n",
            "Epoch 9/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.7271 - accuracy: 0.7862 - val_loss: 1.0007 - val_accuracy: 0.7200\n",
            "Epoch 10/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.8124 - val_loss: 0.9293 - val_accuracy: 0.7250\n",
            "Epoch 11/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.8403 - val_loss: 0.8897 - val_accuracy: 0.7450\n",
            "Epoch 12/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.8593 - val_loss: 0.8313 - val_accuracy: 0.7550\n",
            "Epoch 13/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.8839 - val_loss: 0.8108 - val_accuracy: 0.7700\n",
            "Epoch 14/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8961 - val_loss: 0.7630 - val_accuracy: 0.8000\n",
            "Epoch 15/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3623 - accuracy: 0.9174 - val_loss: 0.7539 - val_accuracy: 0.8050\n",
            "Epoch 16/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.9246 - val_loss: 0.7193 - val_accuracy: 0.8300\n",
            "Epoch 17/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.2878 - accuracy: 0.9341 - val_loss: 0.6783 - val_accuracy: 0.8200\n",
            "Epoch 18/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.2570 - accuracy: 0.9481 - val_loss: 0.6702 - val_accuracy: 0.8300\n",
            "Epoch 19/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.2347 - accuracy: 0.9503 - val_loss: 0.6912 - val_accuracy: 0.8150\n",
            "Epoch 20/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.2118 - accuracy: 0.9564 - val_loss: 0.6481 - val_accuracy: 0.8200\n",
            "Epoch 21/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.1882 - accuracy: 0.9676 - val_loss: 0.6384 - val_accuracy: 0.8400\n",
            "Epoch 22/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.1630 - accuracy: 0.9726 - val_loss: 0.6525 - val_accuracy: 0.8250\n",
            "Epoch 23/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.1491 - accuracy: 0.9743 - val_loss: 0.6836 - val_accuracy: 0.8300\n",
            "Epoch 24/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.1362 - accuracy: 0.9771 - val_loss: 0.6164 - val_accuracy: 0.8450\n",
            "Epoch 25/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9821 - val_loss: 0.6369 - val_accuracy: 0.8450\n",
            "Epoch 26/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.1114 - accuracy: 0.9866 - val_loss: 0.6618 - val_accuracy: 0.8300\n",
            "Epoch 27/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9866 - val_loss: 0.6831 - val_accuracy: 0.8500\n",
            "Epoch 28/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0898 - accuracy: 0.9888 - val_loss: 0.6481 - val_accuracy: 0.8600\n",
            "Epoch 29/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0841 - accuracy: 0.9883 - val_loss: 0.6645 - val_accuracy: 0.8650\n",
            "Epoch 30/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0774 - accuracy: 0.9905 - val_loss: 0.7114 - val_accuracy: 0.8250\n",
            "Epoch 31/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9899 - val_loss: 0.6841 - val_accuracy: 0.8400\n",
            "Epoch 32/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.9950 - val_loss: 0.6705 - val_accuracy: 0.8650\n",
            "Epoch 33/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9905 - val_loss: 0.6685 - val_accuracy: 0.8500\n",
            "Epoch 34/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9961 - val_loss: 0.6751 - val_accuracy: 0.8350\n",
            "Epoch 35/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.9927 - val_loss: 0.6734 - val_accuracy: 0.8600\n",
            "Epoch 36/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9944 - val_loss: 0.6800 - val_accuracy: 0.8500\n",
            "Epoch 37/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9939 - val_loss: 0.6809 - val_accuracy: 0.8450\n",
            "Epoch 38/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9955 - val_loss: 0.7099 - val_accuracy: 0.8700\n",
            "Epoch 39/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9966 - val_loss: 0.7921 - val_accuracy: 0.8150\n",
            "Epoch 40/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9961 - val_loss: 0.7214 - val_accuracy: 0.8650\n",
            "Epoch 41/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9961 - val_loss: 0.7172 - val_accuracy: 0.8550\n",
            "Epoch 42/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.9961 - val_loss: 0.7458 - val_accuracy: 0.8500\n",
            "Epoch 43/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9966 - val_loss: 0.7350 - val_accuracy: 0.8500\n",
            "Epoch 44/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9978 - val_loss: 0.7372 - val_accuracy: 0.8450\n",
            "Epoch 45/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9972 - val_loss: 0.7526 - val_accuracy: 0.8450\n",
            "Epoch 46/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0264 - accuracy: 0.9966 - val_loss: 0.7482 - val_accuracy: 0.8500\n",
            "Epoch 47/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9972 - val_loss: 0.7564 - val_accuracy: 0.8550\n",
            "Epoch 48/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9972 - val_loss: 0.7964 - val_accuracy: 0.8400\n",
            "Epoch 49/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9972 - val_loss: 0.7655 - val_accuracy: 0.8500\n",
            "Epoch 50/50\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9978 - val_loss: 0.7745 - val_accuracy: 0.8500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd5ca4a6d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1O58rlDflI5"
      },
      "source": [
        "def getFaceExpressionFromIndex(i):\n",
        "  if (i == 0):\n",
        "      return 'surprise'\n",
        "  elif (i == 1):\n",
        "      return 'smile'\n",
        "  elif (i == 2):\n",
        "      return 'sad'\n",
        "  elif (i == 3):\n",
        "      return 'anger'\n",
        "  elif (i == 4):\n",
        "      return 'fear'\n",
        "  elif (i == 5):\n",
        "      return 'disgust'\n",
        "  elif (i == 6):\n",
        "      return 'none'\n",
        "  else:\n",
        "      print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETYLUe55fnxb",
        "outputId": "9dfe25d6-5c75-4957-ce3a-9c15fdb7a330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_predictions = model.predict(X_test)\n",
        "correct = 0\n",
        "for i in range(len(test_predictions)):\n",
        "  truth = np.argmax(y_test[i])\n",
        "  prediction = np.argmax(test_predictions[i])\n",
        "  if truth == prediction:\n",
        "    correct += 1\n",
        "  else:\n",
        "    print(f'Wrong classification, truth: {getFaceExpressionFromIndex(truth)}')\n",
        "    print(f'Wrong classification, prediction: {getFaceExpressionFromIndex(prediction)}')\n",
        "    print(\"---------------------------------------------------------------------------\")\n",
        "\n",
        "print(f'Accuracy of predicitons: {correct / len(test_predictions)}')\n",
        "print(f'Got correct: {correct}')\n",
        "print(f'Got wrong: {len(test_predictions) - correct}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrong classification, truth: anger\n",
            "Wrong classification, prediction: sad\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: sad\n",
            "Wrong classification, prediction: disgust\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: smile\n",
            "Wrong classification, prediction: surprise\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: anger\n",
            "Wrong classification, prediction: surprise\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: surprise\n",
            "Wrong classification, prediction: anger\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: none\n",
            "Wrong classification, prediction: fear\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: anger\n",
            "Wrong classification, prediction: smile\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: surprise\n",
            "Wrong classification, prediction: none\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: none\n",
            "Wrong classification, prediction: surprise\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: fear\n",
            "Wrong classification, prediction: sad\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: surprise\n",
            "Wrong classification, prediction: anger\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: none\n",
            "Wrong classification, prediction: surprise\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: anger\n",
            "Wrong classification, prediction: surprise\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: surprise\n",
            "Wrong classification, prediction: smile\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: surprise\n",
            "Wrong classification, prediction: none\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: anger\n",
            "Wrong classification, prediction: smile\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: anger\n",
            "Wrong classification, prediction: surprise\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: anger\n",
            "Wrong classification, prediction: surprise\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: smile\n",
            "Wrong classification, prediction: anger\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: surprise\n",
            "Wrong classification, prediction: none\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: anger\n",
            "Wrong classification, prediction: surprise\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: smile\n",
            "Wrong classification, prediction: none\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: smile\n",
            "Wrong classification, prediction: sad\n",
            "---------------------------------------------------------------------------\n",
            "Wrong classification, truth: surprise\n",
            "Wrong classification, prediction: anger\n",
            "---------------------------------------------------------------------------\n",
            "Accuracy of predicitons: 0.8918918918918919\n",
            "Got correct: 198\n",
            "Got wrong: 24\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}